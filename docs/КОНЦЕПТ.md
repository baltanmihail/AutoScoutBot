1. Что реально есть сейчас (после двух агентов)
Работает и задеплоено на Railway:
bot.py -- оригинальный Telegram-бот. Он загружает CSV, использует GigaChat для RAG-поиска и re-ranking, принимает платежи через Stars. Это MVP, он работает.
Написано, но НЕ подключено, НЕ запущено, НЕ протестировано:
backend/ -- FastAPI-сервер (PostgreSQL-модели, маршруты search/score/admin, миграция из CSV)
scoring/ -- ML-pipeline (proxy-разметка, feature engineering, обучение LightGBM, SHAP-объяснения)
parsers/ -- парсеры ЕГРЮЛ, Checko.ru, Google News
services/api_client.py -- HTTP-клиент для связи бота с FastAPI
Проблемы от двух параллельных агентов:
Есть дубликаты: scoring/predict.py и scoring/predictor.py (оба делают предсказания, но по-разному)
Есть дубликаты: parsers/ на верхнем уровне и backend/parsers/ внутри backend
Бот никак не подключён к новому FastAPI-серверу. bot.py по-прежнему работает по-старому: CSV -> GigaChat RAG -> эвристика.
Модели не обучены (папка scoring/models/ пуста)
Данные не мигрированы в PostgreSQL
Ничего из нового не тестировалось
Вердикт: Код написан, но это каркас. Работает только оригинальный бот.
2. GigaChat API -- оставлять или нет?
Честный ответ: для нового подхода GigaChat почти не нужен.
Вот почему:
Задача	GigaChat сейчас	Новый подход	Стоимость
Скоринг стартапа	re-ranking "оцени от 0 до 100" (плохо)	LightGBM модель на 35 признаках	Бесплатно
Поиск стартапа	GigaChat Embeddings (1024d)	Локальная модель sentence-transformers (384d)	Бесплатно
Генерация ответа	GigaChat формирует текст	Можно оставить для красивых ответов	Lite: бесплатно
Понимание русского	Хорошо	Локальная multilingual модель тоже нормально	--
Мой совет: GigaChat Lite (бесплатный) оставить только для генерации красивых текстовых ответов пользователю. Скоринг и поиск перевести на собственные модели -- они точнее и бесплатны.
3. Google News -- ты прав, это мимо
Полностью согласен. Google News RSS -- это западные источники, они плохо покрывают российский рынок стартапов. Вот что нужно вместо этого:
Правильные источники для российского рынка:
Источник	Что даёт	API/Парсинг	Авторитетность
bo.nalog.ru (БФО ФНС)	Бухгалтерская отчётность: баланс, P&L, отчёт о движении ДС	Открытый API по ИНН	0.99
ЕГРЮЛ (egrul.nalog.ru)	Юридический статус, учредители, уставный капитал	Открытый API	0.95
Федресурс (fedresurs.ru)	Банкротства, реорганизации, залоги	Парсинг	0.95
MOEX API	Котировки акций/облигаций (для тех, кто торгуется)	Открытый API	0.99
РБК (rbc.ru)	Бизнес-новости, аналитика	Парсинг RSS/HTML	0.80
Rusprofile.ru	Сводка по компании: финансы, суды, госконтракты	Парсинг	0.75
ФИПС (fips.ru)	Патентная база	Парсинг	0.95
Checko.ru	Финансовая отчётность (удобный формат)	Парсинг	0.80
Из БФО (бухгалтерской отчётности) можно извлечь десятки финансовых показателей: EBITDA, рентабельность активов (ROA), текущую ликвидность, долговую нагрузку, оборачиваемость и т.д. Это на порядок лучше, чем просто "выручка и прибыль за 6 лет", что есть сейчас в CSV.
Это реализуемо? Да. bo.nalog.ru -- полностью открытый API, данные по ИНН. MOEX тоже даёт бесплатный API. РБК можно парсить. Это нужно просто правильно написать.
4. AI-модель: что, сколько стоит, как содержать
Вот ключевое -- тебе НЕ нужна огромная LLM. Подход из плана использует LightGBM/XGBoost -- это не нейросеть в привычном смысле:
Параметр	LightGBM (наш подход)	LLM (ChatGPT-подобная)
Размер модели	5-50 МБ	10-200 ГБ
Обучение	1-5 мин на ноутбуке	Дни на GPU-кластере
GPU нужен?	Нет	Да, дорого
Inference	< 1 мс на запрос	1-10 сек
Стоимость содержания	0 руб	Тысячи в месяц
Точность на табличных данных	Выше	Ниже (LLM не для таблиц)
LightGBM -- это правильный инструмент для задачи "оценить стартап по 35 числовым/категориальным признакам". LLM (включая GigaChat) для этого плохо подходят.
Что нужно купить/установить:
Ничего специального. pip install lightgbm scikit-learn shap -- всё бесплатное
Модель обучается за минуты прямо на Railway (1 CPU, 512 MB RAM достаточно)
Файл модели: 5-50 МБ, хранится прямо в репозитории или на Railway
Для sentence-transformers (embeddings): модель ~100 МБ, скачивается один раз
Про "закрытую AI-модель, обученную на 5000+ стартапах":
Именно это и делает scoring/train.py -- обучает LightGBM на данных из CSV. Это и есть "закрытая модель" -- она обучена на твоих данных и ни у кого больше такой нет.
5. Что делать на Railway прямо сейчас
Порядок действий:
Убрать мусор от двух агентов -- удалить дубликаты, оставить рабочие версии
Обучить модель локально -- запустить python -m scoring.labeler и python -m scoring.train
Добавить PostgreSQL на Railway -- через Railway Dashboard "Add Plugin > PostgreSQL"
Залить обновлённый код в GitHub -- Railway автоматически задеплоит
Запустить миграцию -- python -m backend.migrate_csv на Railway
Постепенно переключать бота -- на новые API вместо старых эвристик
НО. Бот работает прямо сейчас. Не нужно ломать то, что работает. Переключение должно быть постепенным.
6. Моё представление о проекте
Что: AutoScoutBot -- система AI-скаутинга стартапов, обученная на данных Сколково.
Зачем: Сейчас оценка стартапов -- это ручной труд экспертов (дорого, субъективно, не масштабируется). AutoScoutBot автоматизирует это: 5000 стартапов оценены за секунды, с объяснением каждой оценки.
Для кого:
Венчурные фонды (первичный скрининг dealflow)
Корпоративные акселераторы (Сколково, Сбер, Яндекс)
Инвестиционные аналитики (быстрый due diligence)
Сам Сколтех / Сколково (оценка резидентов)
Как:
Телеграм-бот как интерфейс (уже есть)
LightGBM-модель, обученная на 5000+ стартапах -- объективный скоринг по 6 критериям
Автоматическое обогащение данных из БФО, ЕГРЮЛ, Федресурс, MOEX, РБК
SHAP-объяснения: "Стартап получил 8.5/10 потому что: TRL=7, рост выручки 300%, 5 патентов"
FastAPI backend на Railway (PostgreSQL, pgvector для поиска)
Конкурентное преимущество: Ни у кого в России нет AI-скоринга стартапов на реальных данных. Есть базы (Crunchbase, СПАРК) и консалтинг (Сбер Юнити), но автоматический ML-скоринг с объяснимостью -- это новое.
Что я предлагаю делать дальше
Не параллельно, а последовательно, по одному шагу:
Вычистить дубликаты от двух агентов
Заменить Google News на правильные российские источники (bo.nalog.ru, РБК)
Обучить модель локально и убедиться, что она работает
Поднять PostgreSQL на Railway и мигрировать данные
Подключить бота к FastAPI (постепенно, не ломая текущий функционал)