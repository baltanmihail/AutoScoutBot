"""
Handler for "–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç–∞—Ä—Ç–∞–ø" -- check any startup by INN using external sources.

Flow:
1. User enters /check or presses "–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç–∞—Ä—Ç–∞–ø" button
2. User provides INN or company name
3. Bot searches Skolkovo DB first (ground truth)
4. Concurrently fetches data from external parsers (BFO, EGRUL, MOEX, news, Checko)
5. Extracts features, runs XGBoost model
6. Shows card with ML score and source reliability markers
7. Saves to external_startups DB
"""
from __future__ import annotations

import json
import logging
import re

from aiogram import Router, F, types, Bot
from aiogram.filters import Command
from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton
from aiogram.fsm.context import FSMContext

from states import SkStates
from utils.formatters import escape_html

logger = logging.getLogger(__name__)


def register_check_startup_handlers(
    router: Router,
    bot: Bot,
    user_repository,
    skolkovo_db=None,
):
    """Register handlers for the /check (–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç–∞—Ä—Ç–∞–ø) command."""

    @router.message(Command("check"))
    async def check_startup_cmd(message: types.Message, state: FSMContext):
        user_id = message.from_user.id
        if await user_repository.is_banned(user_id):
            await message.answer("‚ùå –í–∞—à –∞–∫–∫–∞—É–Ω—Ç –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω.")
            return

        await message.answer(
            "üîç <b>–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç–∞—Ä—Ç–∞–ø</b>\n\n"
            "–í–≤–µ–¥–∏—Ç–µ <b>–ò–ù–ù</b> –∫–æ–º–ø–∞–Ω–∏–∏ (10 –∏–ª–∏ 12 —Ü–∏—Ñ—Ä) –∏–ª–∏ <b>–Ω–∞–∑–≤–∞–Ω–∏–µ</b>:",
            parse_mode="HTML",
        )
        await state.set_state(SkStates.CHECK_STARTUP_INPUT)

    @router.callback_query(F.data == "check_startup")
    async def check_startup_btn(query: types.CallbackQuery, state: FSMContext):
        user_id = query.from_user.id
        if await user_repository.is_banned(user_id):
            await query.answer("‚ùå –í–∞—à –∞–∫–∫–∞—É–Ω—Ç –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω", show_alert=True)
            return

        await query.message.edit_text(
            "üîç <b>–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç–∞—Ä—Ç–∞–ø</b>\n\n"
            "–í–≤–µ–¥–∏—Ç–µ <b>–ò–ù–ù</b> –∫–æ–º–ø–∞–Ω–∏–∏ (10 –∏–ª–∏ 12 —Ü–∏—Ñ—Ä) –∏–ª–∏ <b>–Ω–∞–∑–≤–∞–Ω–∏–µ</b>:",
            parse_mode="HTML",
        )
        await state.set_state(SkStates.CHECK_STARTUP_INPUT)
        await query.answer()

    @router.message(SkStates.CHECK_STARTUP_INPUT, F.text)
    async def process_check_input(message: types.Message, state: FSMContext):
        user_input = message.text.strip()
        user_id = message.from_user.id

        # Determine if input is INN or name
        is_inn = bool(re.match(r"^\d{10}(\d{2})?$", user_input))
        inn = user_input if is_inn else ""
        company_name = "" if is_inn else user_input

        wait_msg = await message.answer("‚è≥ –°–æ–±–∏—Ä–∞—é –¥–∞–Ω–Ω—ã–µ –∏–∑ –≤–Ω–µ—à–Ω–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤...")

        # 1. Check Skolkovo ground truth first
        skolkovo_match = None
        if skolkovo_db:
            for startup in skolkovo_db:
                if is_inn and str(startup.get("inn", "")).strip() == inn:
                    skolkovo_match = startup
                    break
                if not is_inn and company_name.lower() in str(startup.get("name", "")).lower():
                    skolkovo_match = startup
                    inn = str(startup.get("inn", ""))
                    break

        # 2. Fetch external data
        external_data = {}
        try:
            from parsers.manager import ParserManager
            mgr = ParserManager()
            if not inn and skolkovo_match:
                inn = str(skolkovo_match.get("inn", ""))
            if inn:
                external_data = await mgr.fetch_all(
                    inn=inn,
                    company_name=company_name or (skolkovo_match or {}).get("name", ""),
                )
            await mgr.close()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –≤–Ω–µ—à–Ω–∏—Ö –¥–∞–Ω–Ω—ã—Ö: {e}")

        # 3. Build response
        response_parts = []

        response_parts.append("‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ")
        response_parts.append(f"üîç <b>–ü—Ä–æ–≤–µ—Ä–∫–∞: {escape_html(company_name or inn)}</b>")
        response_parts.append("‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n")

        if skolkovo_match:
            response_parts.append("‚úÖ <b>–ù–∞–π–¥–µ–Ω –≤ –±–∞–∑–µ –°–∫–æ–ª–∫–æ–≤–æ (Ground Truth)</b>")
            name = skolkovo_match.get("name", "–Ω/–¥")
            response_parts.append(f"  ‚Ä¢ –ù–∞–∑–≤–∞–Ω–∏–µ: {escape_html(name)}")
            response_parts.append(f"  ‚Ä¢ –ö–ª–∞—Å—Ç–µ—Ä: {escape_html(skolkovo_match.get('cluster', '–Ω/–¥'))}")
            response_parts.append(f"  ‚Ä¢ –°—Ç–∞—Ç—É—Å: {escape_html(skolkovo_match.get('status', '–Ω/–¥'))}")
            response_parts.append(f"  ‚Ä¢ –ò–ù–ù: {skolkovo_match.get('inn', '–Ω/–¥')}")

            # Show ML score if available
            try:
                from scoring.ml_scoring import ml_analyze_startup
                analysis = ml_analyze_startup(skolkovo_match)
                if analysis:
                    overall = analysis.get("ml_overall", 0)
                    tl_map = {1: "üî¥", 2: "üü°", 3: "üü¢"}
                    tl = tl_map.get(analysis.get("TrafficLight", 1), "üî¥")
                    response_parts.append(f"\n  {tl} ML-–æ—Ü–µ–Ω–∫–∞: <b>{overall:.1f}/10</b>")
            except Exception:
                pass

            response_parts.append("")

        # 4. External data sections
        egrul = external_data.get("egrul", {})
        if egrul:
            response_parts.append("<b>üìã –ï–ì–†–Æ–õ:</b>")
            response_parts.append(f"  ‚Ä¢ –ù–∞–∑–≤–∞–Ω–∏–µ: {escape_html(egrul.get('name', '–Ω/–¥'))}")
            response_parts.append(f"  ‚Ä¢ –û–ì–†–ù: {egrul.get('ogrn', '–Ω/–¥')}")
            response_parts.append(f"  ‚Ä¢ –°—Ç–∞—Ç—É—Å: {escape_html(egrul.get('status', '–Ω/–¥'))}")
            if egrul.get("registration_date"):
                response_parts.append(f"  ‚Ä¢ –î–∞—Ç–∞ —Ä–µ–≥.: {egrul.get('registration_date')}")
            response_parts.append("")

        bfo = external_data.get("bfo", {})
        if bfo:
            response_parts.append("<b>üí∞ –§–∏–Ω–∞–Ω—Å—ã (–ë–§–û –§–ù–°):</b>")
            financials = bfo.get("financials", {})
            if financials:
                for year in sorted(financials.keys(), reverse=True)[:3]:
                    yd = financials[year]
                    rev = yd.get("revenue", 0)
                    profit = yd.get("net_profit", 0)
                    rev_str = f"{rev / 1_000_000:.1f} –º–ª–Ω" if rev else "–Ω/–¥"
                    profit_str = f"{profit / 1_000_000:.1f} –º–ª–Ω" if profit else "–Ω/–¥"
                    response_parts.append(f"  ‚Ä¢ {year}: –≤—ã—Ä—É—á–∫–∞ {rev_str}, –ø—Ä–∏–±—ã–ª—å {profit_str}")
            else:
                response_parts.append("  ‚Ä¢ –û—Ç—á—ë—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            response_parts.append("")

        checko = external_data.get("checko", {})
        if checko:
            response_parts.append("<b>üìä Checko.ru:</b>")
            if checko.get("revenue"):
                response_parts.append(f"  ‚Ä¢ –í—ã—Ä—É—á–∫–∞: {checko['revenue'] / 1_000_000:.1f} –º–ª–Ω")
            if checko.get("net_profit"):
                response_parts.append(f"  ‚Ä¢ –ß–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å: {checko['net_profit'] / 1_000_000:.1f} –º–ª–Ω")
            if checko.get("employees"):
                response_parts.append(f"  ‚Ä¢ –°–æ—Ç—Ä—É–¥–Ω–∏–∫–∏: {checko['employees']}")
            if checko.get("status"):
                response_parts.append(f"  ‚Ä¢ –°—Ç–∞—Ç—É—Å: {escape_html(checko['status'])}")
            response_parts.append("")

        moex = external_data.get("moex", {})
        if moex and moex.get("has_quotes"):
            response_parts.append("<b>üìà MOEX:</b>")
            response_parts.append(f"  ‚Ä¢ –¢–∏–∫–µ—Ä: {moex.get('ticker', '–Ω/–¥')}")
            if moex.get("last"):
                response_parts.append(f"  ‚Ä¢ –¶–µ–Ω–∞: {moex['last']}")
            if moex.get("marketcap"):
                cap = moex["marketcap"]
                response_parts.append(f"  ‚Ä¢ –ö–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏—è: {cap / 1_000_000_000:.2f} –º–ª—Ä–¥")
            response_parts.append("")

        news = external_data.get("news", {})
        if news and news.get("total_count", 0) > 0:
            response_parts.append(f"<b>üì∞ –£–ø–æ–º–∏–Ω–∞–Ω–∏—è –≤ –°–ú–ò ({news['total_count']}):</b>")
            for mention in news.get("mentions", [])[:3]:
                src = mention.get("source", "").upper()
                title = escape_html(mention.get("title", "")[:100])
                response_parts.append(f"  ‚Ä¢ [{src}] {title}")
            response_parts.append("")

        # 5. ML scoring for external startup (if not in Skolkovo)
        if not skolkovo_match and (bfo or egrul):
            try:
                features = _extract_features_from_external(external_data)
                if features:
                    from scoring.ml_scoring import ml_analyze_startup
                    analysis = ml_analyze_startup(features)
                    if analysis:
                        overall = analysis.get("ml_overall", 0)
                        tl_map = {1: "üî¥", 2: "üü°", 3: "üü¢"}
                        tl = tl_map.get(analysis.get("TrafficLight", 1), "üî¥")
                        response_parts.append(f"{tl} <b>ML-–æ—Ü–µ–Ω–∫–∞ (–Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–Ω–µ—à–Ω–∏—Ö –¥–∞–Ω–Ω—ã—Ö): {overall:.1f}/10</b>")
                        response_parts.append(f"  ‚Ä¢ –ó–∞–ø–æ–ª–Ω–µ–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {features.get('_filled', 0)}/39")
                        response_parts.append(
                            "<i>–¢–æ—á–Ω–æ—Å—Ç—å –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –ø–æ–ª–Ω–æ—Ç—ã –¥–∞–Ω–Ω—ã—Ö. "
                            "–ß–µ–º –±–æ–ª—å—à–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∑–∞–ø–æ–ª–Ω–µ–Ω–æ, —Ç–µ–º –Ω–∞–¥—ë–∂–Ω–µ–µ –æ—Ü–µ–Ω–∫–∞.</i>"
                        )
                        response_parts.append("")
            except Exception as e:
                logger.warning(f"ML scoring –¥–ª—è –≤–Ω–µ—à–Ω–µ–≥–æ —Å—Ç–∞—Ä—Ç–∞–ø–∞: {e}")

        if not skolkovo_match and not external_data:
            response_parts.append("‚ùå –î–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –ò–ù–ù.")

        # Send response
        text = "\n".join(response_parts)
        if len(text) > 4000:
            parts = [text[i:i + 4000] for i in range(0, len(text), 4000)]
            for part in parts:
                await bot.send_message(chat_id=message.chat.id, text=part, parse_mode="HTML")
        else:
            await wait_msg.edit_text(text, parse_mode="HTML")

        # 6. Save external startup to DB for future retraining
        if inn and external_data and not skolkovo_match:
            try:
                _save_external_startup(inn, external_data)
            except Exception as e:
                logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤–Ω–µ—à–Ω–∏–π —Å—Ç–∞—Ä—Ç–∞–ø –≤ –ë–î: %s", e)

        # Navigation keyboard
        keyboard = InlineKeyboardMarkup(
            inline_keyboard=[
                [InlineKeyboardButton(text="üîç –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –µ—â—ë", callback_data="check_startup")],
                [InlineKeyboardButton(text="üìä –ê–Ω–∞–ª–∏–∑ –ø–æ –±–∞–∑–µ", callback_data="analyze")],
            ]
        )
        await bot.send_message(chat_id=message.chat.id, text="–ß—Ç–æ –¥–∞–ª—å—à–µ?", reply_markup=keyboard)

        await state.clear()


def _extract_features_from_external(external_data: dict) -> dict:
    """Build a startup-like dict from external data for ML scoring.

    Returns a dict that mimics the Skolkovo CSV fields as closely as possible,
    filled with whatever data the parsers provided.
    """
    features: dict = {}
    filled = 0

    bfo = external_data.get("bfo", {})
    egrul = external_data.get("egrul", {})
    checko = external_data.get("checko", {})

    # Name
    features["name"] = (
        egrul.get("name")
        or bfo.get("name")
        or checko.get("name", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–ø–∞–Ω–∏—è")
    )

    # INN / OGRN
    features["inn"] = egrul.get("inn", bfo.get("inn", ""))
    features["ogrn"] = egrul.get("ogrn", "")

    # Status
    if egrul.get("is_active") is not None:
        features["status"] = "active" if egrul["is_active"] else "inactive"
        filled += 1

    # Year founded
    reg_date = egrul.get("registration_date", checko.get("registration_date", ""))
    if reg_date:
        import re
        year_match = re.search(r"(\d{4})", str(reg_date))
        if year_match:
            features["year"] = int(year_match.group(1))
            filled += 1

    # Financials from BFO
    financials = bfo.get("financials", {})
    for year in range(2020, 2026):
        year_data = financials.get(year, financials.get(str(year), {}))
        if year_data:
            rev = year_data.get("revenue", 0)
            profit = year_data.get("net_profit", 0)
            if rev:
                features[f"revenue_{year}"] = rev
                filled += 1
            if profit:
                features[f"profit_{year}"] = profit
                filled += 1

    # TRL/IRL/MRL/CRL -- unknown for external, leave at 0
    features["trl"] = 0
    features["mrl"] = 0
    features["irl"] = 0
    features["crl"] = 0

    # Patent count -- unknown
    features["patent_count"] = 0

    # Description
    features["company_description"] = ""
    features["product_description"] = ""
    features["technologies"] = ""

    features["_filled"] = filled
    return features if filled >= 2 else {}


def _save_external_startup(inn: str, external_data: dict) -> None:
    """
    –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤–Ω–µ—à–Ω–µ–≥–æ —Å—Ç–∞—Ä—Ç–∞–ø–∞ –≤ SQLite –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –¥–æ–æ–±—É—á–µ–Ω–∏—è ML.

    –ö–∞–∂–¥—ã–π `/check` –ø–æ–ø–æ–ª–Ω—è–µ—Ç —Ç–∞–±–ª–∏—Ü—É external_startups, –∫–æ—Ç–æ—Ä–∞—è –ø–æ—Ç–æ–º
    –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ scoring/retrain.py –¥–ª—è Semi-Supervised –¥–æ–æ–±—É—á–µ–Ω–∏—è.
    """
    import sqlite3
    import os

    db_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "..", "users.db")
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    cursor.execute("""
        CREATE TABLE IF NOT EXISTS external_startups (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            inn TEXT UNIQUE NOT NULL,
            ogrn TEXT DEFAULT '',
            name TEXT NOT NULL DEFAULT '',
            full_legal_name TEXT DEFAULT '',
            region TEXT DEFAULT '',
            status_egrul TEXT DEFAULT '',
            registration_date TEXT,
            features_json TEXT DEFAULT '{}',
            features_filled_count INTEGER DEFAULT 0,
            ml_overall REAL,
            raw_data_json TEXT DEFAULT '{}',
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """)

    egrul = external_data.get("egrul", {})
    bfo = external_data.get("bfo", {})
    checko = external_data.get("checko", {})

    name = egrul.get("name") or bfo.get("name") or checko.get("name", "")
    ogrn = egrul.get("ogrn", "")
    status = egrul.get("status", "")
    reg_date = egrul.get("registration_date", "")

    features = _extract_features_from_external(external_data)
    filled = features.pop("_filled", 0) if features else 0

    ml_overall = None
    if features:
        try:
            from scoring.ml_scoring import ml_analyze_startup
            analysis = ml_analyze_startup(features)
            if analysis:
                ml_overall = analysis.get("ml_overall")
        except Exception:
            pass

    cursor.execute("""
        INSERT INTO external_startups
            (inn, ogrn, name, status_egrul, registration_date,
             features_json, features_filled_count, ml_overall, raw_data_json)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
        ON CONFLICT(inn) DO UPDATE SET
            name = excluded.name,
            ogrn = excluded.ogrn,
            status_egrul = excluded.status_egrul,
            registration_date = excluded.registration_date,
            features_json = excluded.features_json,
            features_filled_count = excluded.features_filled_count,
            ml_overall = excluded.ml_overall,
            raw_data_json = excluded.raw_data_json,
            updated_at = CURRENT_TIMESTAMP
    """, (
        inn,
        ogrn,
        name,
        status,
        reg_date,
        json.dumps(features, ensure_ascii=False),
        filled,
        ml_overall,
        json.dumps(external_data, ensure_ascii=False, default=str),
    ))

    conn.commit()
    conn.close()
    logger.info("–í–Ω–µ—à–Ω–∏–π —Å—Ç–∞—Ä—Ç–∞–ø —Å–æ—Ö—Ä–∞–Ω—ë–Ω: INN=%s, name=%s, filled=%d", inn, name, filled)
